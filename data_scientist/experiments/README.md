Анализ тональности новостей.

Целью являлось постройка пайплайна для анализа тональности текста новостей.

В качестве модели было принято решение взять rubert-tiny2. Модель на основе архитектуры BERT, оптимизированная для обработки русского языка. Предназначена для решения задач, связанных с анализом текстов на русском языке, например, для обнаружения эмоций или классификации сентимента. 

Используемый датасет после предобраобтки имеет 2 призгнака: text и sentiment.
text - текст новости
sentiment - настроение текста

Все слои модели были заморожены, а обучались только новые слои.

Обучение на cpu было бы достаточно долгое, поэтому было принято решение обучить модель на google colab для того, чтобы испольовать gpu. По этой причине здесь нет финальных результатов, но ниже они были добавлены.(Обучение на 10 эпохах)


              precision    recall  f1-score   support

           0       0.53      0.79      0.64       420
           1       0.66      0.29      0.40       605
           2       0.40      0.64      0.49       215

    accuracy                           0.52      1240
   macro avg       0.53      0.57      0.51      1240
weighted avg       0.57      0.52      0.50      1240


Модель показала точность 0.52, что чуть лучше случайности.Лучше всего определяется класс 0 (recall - 0.79), при этом класс 1 распознаётся хуже всего (recall - 0.29).Класс 2 показывает среднее качество (F1 - 0.49).

После некоторых правок и улучшений значительного повышения качества добиться не получилось. При повышении количества эпох наблюдалось переобучение. Примерно оно начиналось после 13 эпохи.

Результатя показывают, что модель плохо справляется с задачей раздедения на классы.Было принято решение перейти на другой подход с выделением событий, а этот оставить как эксперимент.




